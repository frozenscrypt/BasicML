{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Statements - Numpy, Pandas, Classifiers, Scorers, Metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data in pandas dataframe\n",
    "data = pd.read_csv(\"spambase/spambase.data\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3     4     5     6     7     8     9  ...    48     49  \\\n",
       "0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00 ...  0.00  0.000   \n",
       "1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94 ...  0.00  0.132   \n",
       "2  0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25 ...  0.01  0.143   \n",
       "3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63 ...  0.00  0.137   \n",
       "4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63 ...  0.00  0.135   \n",
       "\n",
       "    50     51     52     53     54   55    56  57  \n",
       "0  0.0  0.778  0.000  0.000  3.756   61   278   1  \n",
       "1  0.0  0.372  0.180  0.048  5.114  101  1028   1  \n",
       "2  0.0  0.276  0.184  0.010  9.821  485  2259   1  \n",
       "3  0.0  0.137  0.000  0.000  3.537   40   191   1  \n",
       "4  0.0  0.135  0.000  0.000  3.537   40   191   1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View rows of data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Classifier objects to test\n",
    "LogReg = LogisticRegression()\n",
    "SVM = SVC()\n",
    "DTC = DecisionTreeClassifier()\n",
    "MNB = MultinomialNB()\n",
    "RFC = RandomForestClassifier(n_estimators=100)\n",
    "XGC = xgb.XGBClassifier(n_estimators = 100,max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that accepts a list of models, data and cross validation turns cv\n",
    "'''Shuffle data and form feature matrix X and labels Y. Perform train-test split on the data. Create a KFold object to\n",
    "segment data into k folds. Here k = cv. Try each model in the list of models. Fit and predict using each model.\n",
    "Print False Positive Rate, False Negative Rate, Overal Error Rate and Average Accuracy across all folds.'''\n",
    "\n",
    "def cross_validate(models,data,cv):\n",
    "    dataShuffled = shuffle(data).reset_index(drop=True)\n",
    "    X = dataShuffled.iloc[:,0:56]\n",
    "    Y = dataShuffled.iloc[:,-1]\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    KF = KFold(n_splits=cv)\n",
    "    for model in models:\n",
    "        print('Model: ',model)\n",
    "        i = 0\n",
    "        sum_accuracy = 0\n",
    "        for train_index, test_index in KF.split(X_train):\n",
    "            print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index))\n",
    "            xtrain, xtest = X_train.iloc[train_index,:], X_train.iloc[test_index,:]\n",
    "            ytrain,ytest = Y_train.iloc[train_index],Y_train.iloc[test_index]\n",
    "            model.fit(xtrain,ytrain)\n",
    "            y_pred = model.predict(xtest)\n",
    "            tn, fp, fn, tp = confusion_matrix(ytest,y_pred).ravel()\n",
    "            print('Fold {} : False Positive Rate = '.format(i),fp/(fp+tn))\n",
    "            print('Fold {} : False Negative Rate = '.format(i),fn/(fn+tp))\n",
    "            print('Fold {} : Overall Error Rate = '.format(i),(fn+fp)/(tn + fp + fn + tp))\n",
    "#             print('Fold {} : F1 Score = '.format(i),f1_score(ytest,y_pred))\n",
    "#             print('Fold {} : Accuracy = '.format(i),accuracy_score(ytest,y_pred))\n",
    "            sum_accuracy += accuracy_score(ytest,y_pred)\n",
    "            i+=1\n",
    "        mean_accuracy = sum_accuracy/cv\n",
    "        print(\"Average Accuracy: \",mean_accuracy)\n",
    "        print('-----------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enlist models to test\n",
    "models = [LogReg,SVM,MNB,DTC,RFC,XGC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "TRAIN: 2760 TEST: 920\n",
      "Fold 0 : False Positive Rate =  0.06261510128913444\n",
      "Fold 0 : False Negative Rate =  0.1246684350132626\n",
      "Fold 0 : Overall Error Rate =  0.08804347826086957\n",
      "TRAIN: 2760 TEST: 920\n",
      "Fold 1 : False Positive Rate =  0.04121863799283154\n",
      "Fold 1 : False Negative Rate =  0.10220994475138122\n",
      "Fold 1 : Overall Error Rate =  0.06521739130434782\n",
      "TRAIN: 2760 TEST: 920\n",
      "Fold 2 : False Positive Rate =  0.046125461254612546\n",
      "Fold 2 : False Negative Rate =  0.12698412698412698\n",
      "Fold 2 : Overall Error Rate =  0.07934782608695652\n",
      "TRAIN: 2760 TEST: 920\n",
      "Fold 3 : False Positive Rate =  0.0625\n",
      "Fold 3 : False Negative Rate =  0.11337209302325581\n",
      "Fold 3 : Overall Error Rate =  0.08152173913043478\n",
      "Average Accuracy:  0.9214673913043478\n",
      "-----------------------------------------------------------\n",
      "Model:  SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "TRAIN: 2760 TEST: 920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vivek\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\vivek\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\vivek\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\vivek\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\vivek\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 : False Positive Rate =  0.07366482504604052\n",
      "Fold 0 : False Negative Rate =  0.10344827586206896\n",
      "Fold 0 : Overall Error Rate =  0.08586956521739131\n",
      "TRAIN: 2760 TEST: 920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vivek\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 : False Positive Rate =  0.06810035842293907\n",
      "Fold 1 : False Negative Rate =  0.11602209944751381\n",
      "Fold 1 : Overall Error Rate =  0.08695652173913043\n",
      "TRAIN: 2760 TEST: 920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vivek\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 : False Positive Rate =  0.06273062730627306\n",
      "Fold 2 : False Negative Rate =  0.1164021164021164\n",
      "Fold 2 : Overall Error Rate =  0.08478260869565217\n",
      "TRAIN: 2760 TEST: 920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vivek\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 : False Positive Rate =  0.10590277777777778\n",
      "Fold 3 : False Negative Rate =  0.125\n",
      "Fold 3 : Overall Error Rate =  0.11304347826086956\n",
      "Average Accuracy:  0.9073369565217391\n",
      "-----------------------------------------------------------\n",
      "Model:  MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "TRAIN: 2760 TEST: 920\n",
      "Fold 0 : False Positive Rate =  0.17679558011049723\n",
      "Fold 0 : False Negative Rate =  0.11140583554376658\n",
      "Fold 0 : Overall Error Rate =  0.15\n",
      "TRAIN: 2760 TEST: 920\n",
      "Fold 1 : False Positive Rate =  0.14336917562724014\n",
      "Fold 1 : False Negative Rate =  0.1850828729281768\n",
      "Fold 1 : Overall Error Rate =  0.15978260869565217\n",
      "TRAIN: 2760 TEST: 920\n",
      "Fold 2 : False Positive Rate =  0.14391143911439114\n",
      "Fold 2 : False Negative Rate =  0.21693121693121692\n",
      "Fold 2 : Overall Error Rate =  0.17391304347826086\n",
      "TRAIN: 2760 TEST: 920\n",
      "Fold 3 : False Positive Rate =  0.16145833333333334\n",
      "Fold 3 : False Negative Rate =  0.2005813953488372\n",
      "Fold 3 : Overall Error Rate =  0.17608695652173914\n",
      "Average Accuracy:  0.835054347826087\n",
      "-----------------------------------------------------------\n",
      "Model:  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "TRAIN: 2760 TEST: 920\n",
      "Fold 0 : False Positive Rate =  0.08839779005524862\n",
      "Fold 0 : False Negative Rate =  0.129973474801061\n",
      "Fold 0 : Overall Error Rate =  0.10543478260869565\n",
      "TRAIN: 2760 TEST: 920\n",
      "Fold 1 : False Positive Rate =  0.08960573476702509\n",
      "Fold 1 : False Negative Rate =  0.10497237569060773\n",
      "Fold 1 : Overall Error Rate =  0.09565217391304348\n",
      "TRAIN: 2760 TEST: 920\n",
      "Fold 2 : False Positive Rate =  0.08671586715867159\n",
      "Fold 2 : False Negative Rate =  0.11904761904761904\n",
      "Fold 2 : Overall Error Rate =  0.1\n",
      "TRAIN: 2760 TEST: 920\n",
      "Fold 3 : False Positive Rate =  0.0954861111111111\n",
      "Fold 3 : False Negative Rate =  0.10755813953488372\n",
      "Fold 3 : Overall Error Rate =  0.1\n",
      "Average Accuracy:  0.8997282608695651\n",
      "-----------------------------------------------------------\n",
      "Model:  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "TRAIN: 2760 TEST: 920\n",
      "Fold 0 : False Positive Rate =  0.03683241252302026\n",
      "Fold 0 : False Negative Rate =  0.0636604774535809\n",
      "Fold 0 : Overall Error Rate =  0.04782608695652174\n",
      "TRAIN: 2760 TEST: 920\n",
      "Fold 1 : False Positive Rate =  0.03046594982078853\n",
      "Fold 1 : False Negative Rate =  0.07734806629834254\n",
      "Fold 1 : Overall Error Rate =  0.04891304347826087\n",
      "TRAIN: 2760 TEST: 920\n",
      "Fold 2 : False Positive Rate =  0.03136531365313653\n",
      "Fold 2 : False Negative Rate =  0.082010582010582\n",
      "Fold 2 : Overall Error Rate =  0.05217391304347826\n",
      "TRAIN: 2760 TEST: 920\n",
      "Fold 3 : False Positive Rate =  0.03993055555555555\n",
      "Fold 3 : False Negative Rate =  0.07848837209302326\n",
      "Fold 3 : Overall Error Rate =  0.05434782608695652\n",
      "Average Accuracy:  0.9491847826086957\n",
      "-----------------------------------------------------------\n",
      "Model:  XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=5, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "TRAIN: 2760 TEST: 920\n",
      "Fold 0 : False Positive Rate =  0.03867403314917127\n",
      "Fold 0 : False Negative Rate =  0.0610079575596817\n",
      "Fold 0 : Overall Error Rate =  0.04782608695652174\n",
      "TRAIN: 2760 TEST: 920\n",
      "Fold 1 : False Positive Rate =  0.025089605734767026\n",
      "Fold 1 : False Negative Rate =  0.07734806629834254\n",
      "Fold 1 : Overall Error Rate =  0.04565217391304348\n",
      "TRAIN: 2760 TEST: 920\n",
      "Fold 2 : False Positive Rate =  0.03505535055350553\n",
      "Fold 2 : False Negative Rate =  0.06613756613756613\n",
      "Fold 2 : Overall Error Rate =  0.04782608695652174\n",
      "TRAIN: 2760 TEST: 920\n",
      "Fold 3 : False Positive Rate =  0.04861111111111111\n",
      "Fold 3 : False Negative Rate =  0.07267441860465117\n",
      "Fold 3 : Overall Error Rate =  0.057608695652173914\n",
      "Average Accuracy:  0.9502717391304348\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#call cross-validate to test all models\n",
    "cross_validate(models,data,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest Classifier is chosen due to its performance on different metrics across many folds against other models\n",
    "RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle data and Split in X and Y\n",
    "dataShuffled = shuffle(data).reset_index(drop=True)\n",
    "X = dataShuffled.iloc[:,0:56]\n",
    "Y = dataShuffled.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No. of folds\n",
    "cv = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: 3680 TEST: 921\n",
      "Fold 0 : False Positive Rate =  0.02831858407079646\n",
      "Fold 0 : False Negative Rate =  0.07303370786516854\n",
      "Fold 0 : Overall Error Rate =  0.04560260586319218\n",
      "TRAIN: 3681 TEST: 920\n",
      "Fold 1 : False Positive Rate =  0.030357142857142857\n",
      "Fold 1 : False Negative Rate =  0.07777777777777778\n",
      "Fold 1 : Overall Error Rate =  0.04891304347826087\n",
      "TRAIN: 3681 TEST: 920\n",
      "Fold 2 : False Positive Rate =  0.03231597845601436\n",
      "Fold 2 : False Negative Rate =  0.07162534435261708\n",
      "Fold 2 : Overall Error Rate =  0.04782608695652174\n",
      "TRAIN: 3681 TEST: 920\n",
      "Fold 3 : False Positive Rate =  0.02460456942003515\n",
      "Fold 3 : False Negative Rate =  0.06552706552706553\n",
      "Fold 3 : Overall Error Rate =  0.04021739130434782\n",
      "TRAIN: 3681 TEST: 920\n",
      "Fold 4 : False Positive Rate =  0.037243947858473\n",
      "Fold 4 : False Negative Rate =  0.08093994778067885\n",
      "Fold 4 : Overall Error Rate =  0.05543478260869565\n",
      "Average Accuracy:  0.9524012179577964\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Use data to evaluate RFC across many folds and print results\n",
    "KF = KFold(n_splits=cv)\n",
    "i = 0\n",
    "sum_accuracy = 0\n",
    "for train_index, test_index in KF.split(X):\n",
    "    print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index))\n",
    "    xtrain, xtest = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "    ytrain,ytest = Y.iloc[train_index],Y.iloc[test_index]\n",
    "    RFC.fit(xtrain,ytrain)\n",
    "    y_pred = RFC.predict(xtest)\n",
    "    tn, fp, fn, tp = confusion_matrix(ytest,y_pred).ravel()\n",
    "    print('Fold {} : False Positive Rate = '.format(i),fp/(fp+tn))\n",
    "    print('Fold {} : False Negative Rate = '.format(i),fn/(fn+tp))\n",
    "    print('Fold {} : Overall Error Rate = '.format(i),(fn+fp)/(tn + fp + fn + tp))\n",
    "\n",
    "    sum_accuracy += accuracy_score(ytest,y_pred)\n",
    "    i+=1\n",
    "mean_accuracy = sum_accuracy/cv\n",
    "print(\"Average Accuracy: \",mean_accuracy)\n",
    "print('-----------------------------------------------------------')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
